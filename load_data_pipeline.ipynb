{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, hamming_loss\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123, 60)\n"
     ]
    }
   ],
   "source": [
    "directory = './regression_modeldata1'\n",
    "\n",
    "with open('groundtruth.json') as json_file:\n",
    "    gtdata = json.load(json_file)\n",
    "subdirs = os.listdir(directory)\n",
    "\n",
    "finalX = []\n",
    "finalyLeft = []\n",
    "finalyRight = []\n",
    "\n",
    "for i in range(len(subdirs)):\n",
    "    dir2pull = directory + '/' + subdirs[i] + '/'\n",
    "    \n",
    "    lefty = gtdata[subdirs[i]]['leftlength']\n",
    "    righty = gtdata[subdirs[i]]['rightlength']\n",
    "    \n",
    "    \n",
    "    for file in glob.glob(dir2pull + '*.csv'):\n",
    "        data2read = file.replace(\"\\\\\",'/')\n",
    "        #print(data2read)\n",
    "        singledata = pd.read_csv(data2read,header=None)\n",
    "        singledata = np.array(singledata)\n",
    "        \n",
    "        dataarray = []\n",
    "        \n",
    "        for j in range(singledata.shape[1]):\n",
    "            if isinstance(singledata[0,j],str):\n",
    "                if singledata[0,j][0:2] == 'SI' or singledata[0,j][0:2]==' S':\n",
    "                    datapoint = singledata[0,j].split('(')[1]\n",
    "                elif singledata[0,j][0:2] == 'L ' or singledata[0,j][0:2] == 'R ':\n",
    "                    datapoint = singledata[0,j][2:]\n",
    "                else:\n",
    "                    datapoint = singledata[0,j].split(')')[0]\n",
    "                datapoint = float(datapoint)\n",
    "            else:\n",
    "                datapoint = singledata[0,j]\n",
    "            dataarray.append(datapoint)\n",
    "        procdata = np.array(dataarray)\n",
    "        #print(procdata.shape)\n",
    "        \n",
    "        if procdata.shape[0] != 60:\n",
    "            continue\n",
    "        \n",
    "        finalX.append(procdata)\n",
    "        finalyLeft.append(lefty + random.uniform(-0.5,0.5))\n",
    "        finalyRight.append(righty + random.uniform(-0.5,0.5))\n",
    "#print(len(finalX))\n",
    "\n",
    "finalX = np.array(finalX)\n",
    "print(finalX.shape)\n",
    "\n",
    "finalyLeft = np.array(finalyLeft)\n",
    "\n",
    "X = finalX\n",
    "#np.random.shuffle(X)\n",
    "y = finalyLeft\n",
    "def shuffle_in_unison(a, b):\n",
    "    n_elem = a.shape[0]\n",
    "    indeces = np.random.choice(n_elem, size=n_elem, replace=False)\n",
    "    return a[indeces], b[indeces]\n",
    "    \n",
    "X,y = shuffle_in_unison(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 60)\n",
      "(13, 60)\n",
      "Train RMSE 0.22635762833350362, Train MAE 0.13548862863503308, Test RMSE 0.8493179947735384, Test MAE 0.5084286745229835\n"
     ]
    }
   ],
   "source": [
    "# with normalized features\n",
    "\n",
    "cv = KFold(n_splits=10,shuffle=True,random_state=234)\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # can comment out break and bring training into loop for cross validation\n",
    "    break\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "    \n",
    "# standard scaler used to z-score\n",
    "normalizer = preprocessing.StandardScaler().fit(X_train)\n",
    "Xpreproc_train = normalizer.transform(X_train)\n",
    "Xpreproc_test = normalizer.transform(X_test)\n",
    "\n",
    "# Now use scikit-learn's random forest regressor to train the model using\n",
    "# the parameters pulled from above\n",
    "#model = LinearRegression().fit(Xpreproc_train,y_train)\n",
    "model = RandomForestRegressor().fit(Xpreproc_train,y_train)\n",
    "#model = GradientBoostingRegressor().fit(Xpreproc_train,y_train)\n",
    "model = model.fit(Xpreproc_train,y_train)\n",
    "\n",
    "# validation metrics calculated here to examine model performance\n",
    "ypred_train = model.predict(Xpreproc_train)\n",
    "ypred_test = model.predict(Xpreproc_test)\n",
    "\n",
    "\n",
    "train_rmse = sqrt(mean_squared_error(y_train[:], ypred_train[:]))\n",
    "test_rmse = sqrt(mean_squared_error(y_test[:],ypred_test[:]))\n",
    "train_mae = mean_absolute_error(y_train[:], ypred_train[:])\n",
    "test_mae = mean_absolute_error(y_test[:],ypred_test[:])\n",
    "\n",
    "print('Train RMSE {}, Train MAE {}, Test RMSE {}, Test MAE {}'.format(train_rmse,train_mae,test_rmse,test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 60)\n",
      "(13, 60)\n",
      "Train RMSE 0.060190380125191414, Train MAE 0.048381828919403604, Test RMSE 0.6912601945728785, Test MAE 0.44120565222246894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaneesh_k/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "['ARLengthModel.pkl']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = KFold(n_splits=10,shuffle=True,random_state=234)\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # can comment out break and bring training into loop for cross validation\n",
    "    break\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "    \n",
    "\n",
    "# Now use scikit-learn's random forest regressor to train the model using\n",
    "# the parameters pulled from above\n",
    "#model = LinearRegression().fit(Xpreproc_train,y_train)\n",
    "#model = RandomForestRegressor().fit(X_train,y_train)\n",
    "model = GradientBoostingRegressor().fit(Xpreproc_train,y_train)\n",
    "model = model.fit(X_train,y_train)\n",
    "\n",
    "# validation metrics calculated here to examine model performance\n",
    "ypred_train = model.predict(X_train)\n",
    "ypred_test = model.predict(X_test)\n",
    "\n",
    "\n",
    "train_rmse = sqrt(mean_squared_error(y_train[:], ypred_train[:]))\n",
    "test_rmse = sqrt(mean_squared_error(y_test[:],ypred_test[:]))\n",
    "train_mae = mean_absolute_error(y_train[:], ypred_train[:])\n",
    "test_mae = mean_absolute_error(y_test[:],ypred_test[:])\n",
    "\n",
    "print('Train RMSE {}, Train MAE {}, Test RMSE {}, Test MAE {}'.format(train_rmse,train_mae,test_rmse,test_mae))\n",
    "\n",
    "# save model to file\n",
    "from sklearn.externals import joblib\n",
    "joblib_file = \"ARLengthModel.pkl\"\n",
    "joblib.dump(model, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TensorFlow version 2.0.0 detected. Last version known to be fully compatible is 1.14.0 .\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Imputer' from 'sklearn.preprocessing' (/Users/vaneesh_k/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/sklearn/preprocessing/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-d02fd02bc23d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcoremltools\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mcoreml_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcoremltools\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mcoreml_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'ardata2length.mlmodel'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/coremltools/converters/sklearn/_converter.py\u001B[0m in \u001B[0;36mconvert\u001B[0;34m(sk_obj, input_features, output_feature_names)\u001B[0m\n\u001B[1;32m    143\u001B[0m     \u001B[0;31m# several issues with the ordering of the classes are worked out.  For now,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m     \u001B[0;31m# to use custom class labels, directly import the internal function below.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 145\u001B[0;31m     \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0m_converter_internal\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_convert_sklearn_model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    146\u001B[0m     spec = _convert_sklearn_model(\n\u001B[1;32m    147\u001B[0m             sk_obj, input_features, output_feature_names, class_labels = None)\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/coremltools/converters/sklearn/_converter_internal.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_logistic_regression\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_normalizer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 42\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_imputer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     43\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_random_forest_classifier\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_random_forest_regressor\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/coremltools/converters/sklearn/_imputer.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0m_HAS_SKLEARN\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0;32mimport\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m     \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpreprocessing\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mImputer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m     \u001B[0mmodel_type\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'transformer'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0msklearn_class\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpreprocessing\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mImputer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'Imputer' from 'sklearn.preprocessing' (/Users/vaneesh_k/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/sklearn/preprocessing/__init__.py)"
     ]
    }
   ],
   "source": [
    "# not tested on an apple computer, may need adjustment\n",
    "\n",
    "import coremltools\n",
    "\n",
    "coreml_model = coremltools.converters.sklearn.convert(model)\n",
    "coreml_model.save('ardata2length.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-37187e8b",
   "language": "python",
   "display_name": "PyCharm (handson-ml2)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}