{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "from numpy import linalg as LA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./regression_modeldata1/sharma/\n",
      "./regression_modeldata1/alex/\n",
      "./regression_modeldata1/senthil/\n",
      "./regression_modeldata1/vaneesh/\n",
      "./regression_modeldata1/user1/\n",
      "(84, 60)\n"
     ]
    }
   ],
   "source": [
    "directory = './regression_modeldata1'\n",
    "\n",
    "with open('groundtruth.json') as json_file:\n",
    "    gtdata = json.load(json_file)\n",
    "subdirs = os.listdir(directory)\n",
    "\n",
    "finalX = []\n",
    "finalyLeft = []\n",
    "finalyRight = []\n",
    "\n",
    "for i in range(len(subdirs)):\n",
    "    dir2pull = directory + '/' + subdirs[i] + '/'\n",
    "    print(dir2pull)\n",
    "    \n",
    "    lefty = gtdata[subdirs[i]]['leftlength']\n",
    "    righty = gtdata[subdirs[i]]['rightlength']\n",
    "    \n",
    "    \n",
    "    for file in glob.glob(dir2pull + '*.csv'):\n",
    "        data2read = file.replace(\"\\\\\",'/')\n",
    "        #print(data2read)\n",
    "        singledata = pd.read_csv(data2read,header=None)\n",
    "        singledata = np.array(singledata)\n",
    "        \n",
    "        dataarray = []\n",
    "        \n",
    "        for j in range(singledata.shape[1]):\n",
    "            if isinstance(singledata[0,j],str):\n",
    "                if singledata[0,j][0:2] == 'SI' or singledata[0,j][0:2]==' S':\n",
    "                    datapoint = singledata[0,j].split('(')[1]\n",
    "                elif singledata[0,j][0:2] == 'L ' or singledata[0,j][0:2] == 'R ':\n",
    "                    datapoint = singledata[0,j][2:]\n",
    "                else:\n",
    "                    datapoint = singledata[0,j].split(')')[0]\n",
    "                datapoint = float(datapoint)\n",
    "            else:\n",
    "                datapoint = singledata[0,j]\n",
    "            dataarray.append(datapoint)\n",
    "        procdata = np.array(dataarray)\n",
    "        #print(procdata.shape)\n",
    "        \n",
    "        if procdata.shape[0] != 60:\n",
    "            continue\n",
    "            \n",
    "        if procdata[6] == 0:\n",
    "            continue\n",
    "        \n",
    "        finalX.append(procdata)\n",
    "        finalyLeft.append(lefty + random.uniform(-0.5,0.5))\n",
    "        finalyRight.append(righty + random.uniform(-0.5,0.5))\n",
    "#print(len(finalX))\n",
    "\n",
    "finalX = np.array(finalX)\n",
    "print(finalX.shape)\n",
    "\n",
    "finalyLeft = np.array(finalyLeft)\n",
    "finalyRight = np.array(finalyRight)\n",
    "\n",
    "X = finalX\n",
    "#np.random.shuffle(X)\n",
    "y = finalyRight\n",
    "def shuffle_in_unison(a, b):\n",
    "    n_elem = a.shape[0]\n",
    "    indeces = np.random.choice(n_elem, size=n_elem, replace=False)\n",
    "    return a[indeces], b[indeces]\n",
    "    \n",
    "X,y = shuffle_in_unison(X,y)\n",
    "\n",
    "def shuffle_in_unison_three(a, b, c):\n",
    "    n_elem = a.shape[0]\n",
    "    indeces = np.random.choice(n_elem, size=n_elem, replace=False)\n",
    "    return a[indeces], b[indeces], c[indeces]\n",
    "\n",
    "X,yL,yR = shuffle_in_unison_three(X,finalyLeft,finalyRight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     y1 baseline\n",
      "1                     y2 baseline\n",
      "2                     x1 baseline\n",
      "3                     x2 baseline\n",
      "4                     z1 baseline\n",
      "5                     z2 baseline\n",
      "6            distance from camera\n",
      "7            left toe y cordinate\n",
      "8            left toe x cordinate\n",
      "9            left toe z cordinate\n",
      "10               left foot length\n",
      "11          right toe y cordinate\n",
      "12          right toe x cordinate\n",
      "13          right toe z cordinate\n",
      "14              right foot length\n",
      "15         camera grain intensity\n",
      "16    transformation matrix (4x4)\n",
      "17    transformation matrix (4x4)\n",
      "18    transformation matrix (4x4)\n",
      "19    transformation matrix (4x4)\n",
      "20    transformation matrix (4x4)\n",
      "21    transformation matrix (4x4)\n",
      "22    transformation matrix (4x4)\n",
      "23    transformation matrix (4x4)\n",
      "24    transformation matrix (4x4)\n",
      "25    transformation matrix (4x4)\n",
      "26    transformation matrix (4x4)\n",
      "27    transformation matrix (4x4)\n",
      "28    transformation matrix (4x4)\n",
      "29    transformation matrix (4x4)\n",
      "30    transformation matrix (4x4)\n",
      "31    transformation matrix (4x4)\n",
      "32                 euler angle x \n",
      "33                 euler angle y \n",
      "34                 euler angle z \n",
      "35                intrinsics(3x3)\n",
      "36                intrinsics(3x3)\n",
      "37                intrinsics(3x3)\n",
      "38                intrinsics(3x3)\n",
      "39                intrinsics(3x3)\n",
      "40                intrinsics(3x3)\n",
      "41                intrinsics(3x3)\n",
      "42                intrinsics(3x3)\n",
      "43                intrinsics(3x3)\n",
      "44        projection matrix (4x4)\n",
      "45        projection matrix (4x4)\n",
      "46        projection matrix (4x4)\n",
      "47        projection matrix (4x4)\n",
      "48        projection matrix (4x4)\n",
      "49        projection matrix (4x4)\n",
      "50        projection matrix (4x4)\n",
      "51        projection matrix (4x4)\n",
      "52        projection matrix (4x4)\n",
      "53        projection matrix (4x4)\n",
      "54        projection matrix (4x4)\n",
      "55        projection matrix (4x4)\n",
      "56        projection matrix (4x4)\n",
      "57        projection matrix (4x4)\n",
      "58        projection matrix (4x4)\n",
      "59        projection matrix (4x4)\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "featurenames = pd.read_csv('ModelDataTemplate.csv',header=None)\n",
    "featurenames = featurenames.iloc[0,:]\n",
    "print(featurenames)\n",
    "\n",
    "\n",
    "# baseline -> left toe xyz = 100\n",
    "# ground truth left = 27cm\n",
    "\n",
    "# baseline -> new xyz = 90\n",
    "# groundtruth != 24.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X[0,:])\n",
    "\n",
    "# 27.5 cm.    /    26.6     =  22      /  x\n",
    "# real_gt / translate_gt = real_ar / translate_ar\n",
    "\n",
    "\n",
    "def dist_pt2line(linept1,linept2,toept):\n",
    "    return LA.norm(np.cross(linept2-linept1, linept1-toept))/LA.norm(linept2-linept1)\n",
    "\n",
    "def compute_translategt(real_gt):\n",
    "    \n",
    "    minlength = 0.23\n",
    "    maxlength = 0.29\n",
    "    adjust_pad = 0.004\n",
    "    \n",
    "    translate_gt = []\n",
    "    \n",
    "    current_length = real_gt\n",
    "    \n",
    "    while current_length > minlength:\n",
    "        translate_gt.append(current_length - adjust_pad)\n",
    "        current_length -= adjust_pad\n",
    "    \n",
    "    current_length = real_gt\n",
    "    \n",
    "    while current_length < maxlength:\n",
    "        translate_gt.append(current_length + adjust_pad)\n",
    "        current_length += adjust_pad\n",
    "    \n",
    "    return translate_gt\n",
    "    \n",
    "    \n",
    "def compute_translatear(real_gt, translate_gt, real_ar):\n",
    "    \n",
    "    translate_ar = []\n",
    "    \n",
    "    for i in range(len(translate_gt)):\n",
    "        translate_ar.append(real_ar * translate_gt[i] / real_gt)\n",
    "    \n",
    "    return translate_ar\n",
    "    \n",
    "    \n",
    "def compute_new_xz(A,toept,translatear, realar, baselinept1=None,baselinept2=None):\n",
    "    \n",
    "    xzpts = []\n",
    "    \n",
    "    for i in range(len(translatear)):\n",
    "        d2translate = realar - translatear[i]\n",
    "        x,z = (toept[1],toept[2]) - d2translate*A\n",
    "        \n",
    "        xzpts.append([x,z])\n",
    "        \n",
    "        if baselinept1 is not None:\n",
    "            print('index {}'.format(i))\n",
    "            print(realar)\n",
    "            print(translatear[i])\n",
    "            print(d2translate)\n",
    "            print(dist_pt2line(baselinept1,baselinept2,toept))\n",
    "            print(dist_pt2line(baselinept1,baselinept2,(toept[0],x,z)))\n",
    "        \n",
    "    return xzpts\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def generate_moredata(X2augment, yleft2augment, yright2augment):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    realleft_gt = yleft2augment / 1000\n",
    "    realright_gt = yright2augment / 1000\n",
    "    \n",
    "    left_translate_gt = compute_translategt(realleft_gt)\n",
    "    right_translate_gt = compute_translategt(realright_gt)\n",
    "    \n",
    "    left_real_ar = X2augment[10]\n",
    "    right_real_ar = X2augment[14]\n",
    "    \n",
    "    #print(left_real_ar)\n",
    "    \n",
    "    \n",
    "    left_translate_ar = compute_translatear(realleft_gt, left_translate_gt, left_real_ar)\n",
    "    right_translate_ar = compute_translatear(realright_gt, right_translate_gt, right_real_ar)\n",
    "    #print(left_translate_ar)\n",
    "    \n",
    "    \n",
    "    baselinept1 = np.array((X2augment[0],X2augment[2],X2augment[4])) # y,x,z\n",
    "    baselinept2 = np.array((X2augment[1],X2augment[3],X2augment[5]))\n",
    "    \n",
    "    lefttoept = np.array((X2augment[7],X2augment[8],X2augment[9]))\n",
    "    righttoept = np.array((X2augment[11],X2augment[12],X2augment[13]))\n",
    "    \n",
    "    #print(dist_pt2line(baselinept1,baselinept2,lefttoept))\n",
    "    \n",
    "#     orig_dist_left = dist_pt2line(baselinept1,baselinept2,lefttoept)\n",
    "#     orig_dist_right = dist_pt2line(baselinept1,baselinept2,righttoept)\n",
    "    \n",
    "#     print(orig_dist_left)\n",
    "#     print('Original left length {}'.format(X2augment[10]))\n",
    "    \n",
    "    dx = baselinept2[1]-baselinept1[1]\n",
    "    dy = baselinept2[2]-baselinept1[2]\n",
    "    \n",
    "    dist = np.sqrt(dx*dx + dy*dy)\n",
    "    dx /= dist\n",
    "    dy /= dist\n",
    "    \n",
    "\n",
    "    A = np.array((dy,-dx))\n",
    "    \n",
    "    #test = compute_new_xz(A,lefttoept,left_translate_ar, left_real_ar, baselinept1,baselinept2)\n",
    "    \n",
    "    left_xz_pts = compute_new_xz(A,lefttoept,left_translate_ar, left_real_ar)\n",
    "    right_xz_pts = compute_new_xz(A,righttoept,right_translate_ar, right_real_ar)\n",
    "    \n",
    "    augmentedX = []\n",
    "    augmentedyleft = []\n",
    "    augmentedyright = []\n",
    "    \n",
    "    for i in range(len(left_translate_ar)):\n",
    "        for j in range(len(right_translate_ar)):\n",
    "            Xcopy = np.array(X2augment[:])\n",
    "            #print(left_xz_pts)\n",
    "            \n",
    "            #print(Xcopy)\n",
    "            \n",
    "            Xcopy[8] = left_xz_pts[i][0]\n",
    "            Xcopy[9] = left_xz_pts[i][1]\n",
    "            Xcopy[10] = left_translate_ar[i]\n",
    "            Xcopy[12] = right_xz_pts[j][0]\n",
    "            Xcopy[13] = right_xz_pts[j][1]\n",
    "            Xcopy[14] = right_translate_ar[j]\n",
    "            \n",
    "            augmentedX.append(Xcopy)\n",
    "            \n",
    "            #augmentedy.append([left_translate_gt[i],right_translate_gt[j]])\n",
    "            augmentedyleft.append(left_translate_gt[i])\n",
    "            augmentedyright.append(right_translate_gt[j])\n",
    "    \n",
    "    \n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.scatter(baselinept1[1],baselinept1[2],c='r')\n",
    "#     plt.scatter(baselinept2[1],baselinept2[2],c='r')\n",
    "#     plt.scatter(newpoint[0],newpoint[1],c='b')\n",
    "#     plt.scatter(lefttoept[1],lefttoept[2],c='g')\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "    return augmentedX, augmentedyleft, augmentedyright\n",
    "#newX, newy = generate_moredata(X[0,:], yL[0], yR[0])\n",
    "#print(np.array(newX)[:,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21504, 60)\n",
      "(21504,)\n"
     ]
    }
   ],
   "source": [
    "X_complete = []\n",
    "y_complete_left = []\n",
    "y_complete_right = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    newX, newyleft, newyright = generate_moredata(X[i,:],yL[i],yR[i])\n",
    "    \n",
    "    X_complete += newX\n",
    "    y_complete_left += newyleft\n",
    "    y_complete_right += newyright\n",
    "    \n",
    "    \n",
    "print(np.array(X_complete).shape)\n",
    "print(np.array(y_complete_left).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19353, 60)\n",
      "(2151, 60)\n",
      "Train RMSE 0.19762220955575294, Train MAE 0.1468626660444538, Test RMSE 0.2615659431738249, Test MAE 0.16963584252474626\n"
     ]
    }
   ],
   "source": [
    "# feature selection/removal\n",
    "\n",
    "#X = X[:,0:15]\n",
    "\n",
    "X = np.array(X_complete)\n",
    "yL = np.array(y_complete_left) * 1000\n",
    "yR = np.array(y_complete_right) * 1000\n",
    "\n",
    "#X,yL,yR = shuffle_in_unison_three(X,yL,yR)\n",
    "\n",
    "cv = KFold(n_splits=10,shuffle=True,random_state=234)\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    #y_train, y_test = yL[train_index], yL[test_index]\n",
    "    y_train, y_test = yR[train_index], yR[test_index]\n",
    "    \n",
    "#     yL_train, yL_test = yL[train_index], yL[test_index]\n",
    "#     yR_train, yR_test = yR[train_index], yR[test_index]\n",
    "    \n",
    "#     yL_train = np.expand_dims(yL_train,axis=1)\n",
    "#     yR_train = np.expand_dims(yR_train,axis=1)\n",
    "    \n",
    "#     yL_test = np.expand_dims(yL_test,axis=1)\n",
    "#     yR_test = np.expand_dims(yR_test,axis=1)\n",
    "    \n",
    "#     y_train = np.concatenate((yL_train,yR_train),axis=1)\n",
    "#     y_test = np.concatenate((yL_test,yR_test),axis=1)                 \n",
    "    \n",
    "    # can comment out break and bring training into loop for cross validation\n",
    "    break\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "    \n",
    "\n",
    "# Now use scikit-learn's random forest regressor to train the model using\n",
    "# the parameters pulled from above\n",
    "#model = LinearRegression().fit(Xpreproc_train,y_train)\n",
    "#model = RandomForestRegressor().fit(X_train,y_train)\n",
    "model = GradientBoostingRegressor(n_estimators=200, max_depth=7).fit(X_train, y_train)\n",
    "#model = GradientBoostingRegressor(n_estimators = 500, max_depth=5, \n",
    "#                                   min_samples_split = 3, min_samples_leaf=5).fit(X_train,y_train)\n",
    "\n",
    "# submodel = GradientBoostingRegressor(n_estimators = 500, max_depth=10, \n",
    "#                                      min_samples_split = 5, min_samples_leaf=1)\n",
    "# model = MultiOutputRegressor(submodel).fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#model = model.fit(X_train,y_train)\n",
    "\n",
    "# validation metrics calculated here to examine model performance\n",
    "ypred_train = model.predict(X_train)\n",
    "ypred_test = model.predict(X_test)\n",
    "\n",
    "\n",
    "train_rmse = sqrt(mean_squared_error(y_train[:], ypred_train[:]))\n",
    "test_rmse = sqrt(mean_squared_error(y_test[:],ypred_test[:]))\n",
    "train_mae = mean_absolute_error(y_train[:], ypred_train[:])\n",
    "test_mae = mean_absolute_error(y_test[:],ypred_test[:])\n",
    "\n",
    "print('Train RMSE {}, Train MAE {}, Test RMSE {}, Test MAE {}'.format(train_rmse,train_mae,test_rmse,test_mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0 feature: right foot length, index 14\n",
      "Percentage important: 0.6130493762157019\n",
      "Top 1 feature: camera grain intensity, index 15\n",
      "Percentage important: 0.0644320775461067\n",
      "Top 2 feature: distance from camera, index 6\n",
      "Percentage important: 0.025319463124071954\n",
      "Top 3 feature: transformation matrix (4x4), index 22\n",
      "Percentage important: 0.024354188858420427\n",
      "Top 4 feature: euler angle y , index 33\n",
      "Percentage important: 0.024023452588134448\n",
      "Top 5 feature: left toe y cordinate, index 7\n",
      "Percentage important: 0.01913024471977998\n",
      "Top 6 feature: transformation matrix (4x4), index 21\n",
      "Percentage important: 0.015955502530322244\n",
      "Top 7 feature: transformation matrix (4x4), index 20\n",
      "Percentage important: 0.015914949571168964\n",
      "Top 8 feature: euler angle x , index 32\n",
      "Percentage important: 0.014829725200836289\n",
      "Top 9 feature: left toe x cordinate, index 8\n",
      "Percentage important: 0.014376177175806859\n"
     ]
    }
   ],
   "source": [
    "importance_values = model.feature_importances_\n",
    "sort_importances = np.argsort(-importance_values)\n",
    "\n",
    "for i in range(10):\n",
    "    print('Top {} feature: {}, index {}'.format(i,featurenames.iloc[sort_importances[i]],sort_importances[i]))\n",
    "    print('Percentage important: {}'.format(importance_values[sort_importances[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools\n",
    "\n",
    "coreml_model = coremltools.converters.sklearn.convert(model)\n",
    "coreml_model.save('ardata2length_right.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
